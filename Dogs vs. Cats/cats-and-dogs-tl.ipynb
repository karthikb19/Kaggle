{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip '../input/dogs-vs-cats/train.zip' -d '/tmp/cats-vs-dogs'\n",
    "!unzip '../input/dogs-vs-cats/test1.zip' -d '/tmp/cats-vs-dogs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = '/tmp/cats-vs-dogs/'\n",
    "train_loc = base + 'train/'\n",
    "test_loc = base + 'test1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = os.listdir(train_loc)\n",
    "categories = []\n",
    "for file in train_files:\n",
    "    val = file.split('.')[0]\n",
    "    if(val == 'dog'):\n",
    "        categories.append(1)\n",
    "    else:\n",
    "        categories.append(0)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'files' : train_files,\n",
    "    'class': categories\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(16, 16))\n",
    "columns = 4\n",
    "rows = 5\n",
    "i=1\n",
    "for filename in os.listdir(train_loc)[0:20]:\n",
    "    image = mpl.image.imread(train_loc + filename)\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow(image)\n",
    "    i+=1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "def read_images_from_dataframe(df, IMAGE_DIR, file_col='files', class_col='class', class_mode='raw',\n",
    "                               target_size=(224, 224), batch_size=32, shuffle=True, validation_split=0.2):\n",
    "    img_datagen = ImageDataGenerator(rescale=1. / 255,\n",
    "                                     validation_split=validation_split)\n",
    "\n",
    "    train_generator = img_datagen.flow_from_dataframe(df,\n",
    "                                                      directory=IMAGE_DIR,\n",
    "                                                      x_col=file_col,\n",
    "                                                      y_col=class_col,\n",
    "                                                      target_size=target_size,\n",
    "                                                      batch_size=batch_size,\n",
    "                                                      shuffle=shuffle,\n",
    "                                                      class_mode=class_mode,\n",
    "                                                      subset='training')\n",
    "\n",
    "    test_generator = img_datagen.flow_from_dataframe(df,\n",
    "                                                     directory=IMAGE_DIR,\n",
    "                                                     x_col=file_col,\n",
    "                                                     y_col=class_col,\n",
    "                                                     target_size=target_size,\n",
    "                                                     batch_size=batch_size,\n",
    "                                                     shuffle=shuffle,\n",
    "                                                     class_mode=class_mode,\n",
    "                                                     subset='validation')\n",
    "\n",
    "    return train_generator, test_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_gen, test_gen = read_images_from_dataframe(df, train_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "\n",
    "model = keras.Sequential()\n",
    "\n",
    "model.add(keras.applications.resnet50.ResNet50(weights = 'imagenet', include_top=False))\n",
    "\n",
    "model.add(keras.layers.GlobalAveragePooling2D())\n",
    "\n",
    "model.add(keras.layers.Dense(64, activation=\"relu\"))\n",
    "\n",
    "model.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(lr=3e-4), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[0].layers:\n",
    "    if layer.name == 'conv5_block1_0_conv':\n",
    "        break\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(tr_gen, validation_data=test_gen, epochs=5, \n",
    "                    steps_per_epoch=tr_gen.n//tr_gen.batch_size,\n",
    "                   validation_steps=test_gen.n//test_gen.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filenames = os.listdir(test_loc)\n",
    "\n",
    "test_df = pd.DataFrame({\n",
    "    'files' : test_filenames\n",
    "})\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "off_test_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "off_test_generator = off_test_gen.flow_from_dataframe(test_df, test_loc, x_col=\"files\", y_col=None, class_mode=None, batch_size=32, target_size=(224, 224), shuffle=False)\n",
    "\n",
    "tsamples = test_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(off_test_generator, steps=np.ceil(tsamples/32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "test_df['category'] = np.where(predictions > threshold, 1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df\n",
    "\n",
    "ans = test_df.copy()\n",
    "\n",
    "ans[\"label\"] = ans[\"category\"]\n",
    "\n",
    "ans[\"id\"] = range(1, 12501)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = ans.drop(['files', 'category'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans[ans.columns[::-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans.to_csv(\"sub.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
